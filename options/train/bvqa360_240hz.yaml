
##################################################################################################################

# Li Yang, Beihang university, 2021.10.21
# General settings of ProVQA
# When using this file, you should modify the path of dataset, related files, experiment directory and models, etc.
# If you have any questions, contact me at 13021041@buaa.edu.cn

##################################################################################################################

name: 0718_yl_train_BVQA360_Basic_ODV-VQA240 # 溶解：改训练的实验名字
model_type: BVQA360Model # 溶解：改模型 对应于model目录下
scale: 1
num_gpu: 2  # set num_gpu: 0 for cpu mode
manual_seed: ~
dist: false
# dataset and data loader settings
datasets:
  train:
    name: odv-vqa240_train # 溶解：改不同的数据库类型名字
    type: ODVVQA240Dataset # 溶解：改不同的数据库类型 对应于data目录下
    dataroot_lq: /raid/yl/data_bvqa_lc_resize/data_vqa_yl240_lmdb_train/odv240-vqa_dataset_train.lmdb # dropbox 下载
    dataroot_flow: ~
    meta_info_file: /raid/yl/data_bvqa_lc_resize/data_vqa_yl240_lmdb_train/odv240-vqa_dataset_train.lmdb/meta_info.txt # dropbox 下载
    train_odv240_info_file: /home/yl/bvqa360_240hz/data/train_240ODV.txt # 这个项目里有
    io_backend:
      type: lmdb

    num_frame: 6 # 溶解：改不同的帧数
    #gt_size: 256
    interval_list: [3] # 溶解：改不同的帧间隔
    random_reverse: false
    use_flip: false
    use_rot: false

    # data loader
    use_shuffle: true
    num_worker_per_gpu: 3  #####
    batch_size_per_gpu: 3 # change to 8
    dataset_enlarge_ratio: 1
    prefetch_mode: ~

#  val:
#    name: REDS4
#    type: VideoTestDataset
#    dataroot_gt: /mnt/minglang/all_data_dir/train_test/small_test/raw/ # /mnt/ywz/database/png_train/test/raw
#    dataroot_lq: /mnt/minglang/all_data_dir/train_test/small_test/QP/ # /mnt/ywz/database/png_train/test/QP
#    # meta_info_file: basicsr/data/meta_info/meta_info_REDS4_test_GT.txt
#    # change to 'meta_info_REDSofficial4_test_GT' when use the official validation partition
#    io_backend:
#      type: disk
#
#    cache_data: false
#    num_frame: 5
#    padding: reflection_circle

# network structures
network_g:
  type: BVQA360v240 # BVQA360 # 溶解实验改 对应 basicsr/models/archs/bvqa360v240_arch.py
  in_channel: 32
  out_channels: [64, 64, 64]
  res_blocks: [3, 4, 6]
  spa3_in: 64
  spa3_out: 32
  comb_in: 64
  motion_comb1: 32
  motion_comb2: 64
  motion_in: 6
  layers: [2, 2, 2, 2]
  nonlocal_in: 32
  mos_in: 32
  num_frame: 6
  fc_dim1: 20


path:
  pretrain_network_g: /raid/yl/bvqa360_experiments/experiments/0718_yl_train_BVQA360_Basic_ODV-VQA240/models/net_g_51000.pth # 如果从头训练的话 这里写 ~ ；如果断点继续训练，就写对应的.pth
  strict_load_g: true
  resume_state: /raid/yl/bvqa360_experiments/experiments/0718_yl_train_BVQA360_Basic_ODV-VQA240/training_states/51000.state  # 如果从头训练的话 这里写 ~ ；如果断点继续训练，就写对应的.state
  experiment_media: /raid/yl/bvqa360_experiments # Set your own experiment path

# training settings
train:
  optim_g:
    type: Adam
    lr: !!float 3e-4 # ml changge from 4e-4 to 2e-4 # the 30.24 version is 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: CosineAnnealingRestartLR
    periods: [50000, 100000, 150000, 150000, 150000]
    restart_weights: [1, 0.5, 0.5, 0.5, 0.5]
    eta_min: !!float 1e-7

  total_iter: 900000
  warmup_iter: -1  # no warm up
  #tsa_iter: 80000 # ml change from 50000 to 500 for debug
  #dcn_lr_mul: 1

  # losses
  pixel_opt:
    type: MSELoss
    loss_weight: 1.0
    reduction: sum

# validation settings
#val:
#  val_freq: !!float 5e3 # ml change from 5e3 to 5e2 for debug
#  save_img: false
#
#  metrics:
#    psnr: # metric name, can be arbitrary
#      type: calculate_psnr
#      crop_border: 0
#      test_y_channel: false
tb_pth: /raid/yl/tb_logger360/
# logging settings
logger:
  print_freq: 10
  save_checkpoint_freq: !!float 3e2
  use_tb_logger: true # 不用tb
  wandb:
    project: ~
    resume_id: ~

# dist training settings
dist_params:
  backend: nccl
  port: 29500

find_unused_parameters: true

# python train.py -opt ../options/train/ml_edvr/ml_train_EDVR_L_debur_REDS.yml
# CUDA_VISIBLE_DEVICES=0,1,2 python train.py -opt /home/yl/bvqa360/options/train/bvqa360.yaml
